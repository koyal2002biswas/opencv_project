{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353f8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c834b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf36d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing=mp.solutions.drawing_utils\n",
    "drawing_styles=mp.solutions.drawing_styles\n",
    "mphands=mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84fb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "hands=mphands.Hands()\n",
    "with mphands.Hands(min_detection_confidence=0.5,\n",
    "                   min_tracking_confidence=0.5,\n",
    "                  max_num_hands=5) as hands:\n",
    "    \n",
    "    while True:\n",
    "        data,img=cap.read()\n",
    "        a=False\n",
    "        b=False\n",
    "        if data==True:\n",
    "            img=cv2.cvtColor(cv2.flip(img,1),cv2.COLOR_BGR2RGB)\n",
    "            results=hands.process(img)\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            ####\n",
    "            c_list=faceCascade.detectMultiScale(\n",
    "                img,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30,30)\n",
    "            )\n",
    "            for (x,y,w,h) in c_list:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                a=True\n",
    "            ###\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    drawing.draw_landmarks(\n",
    "                    img,\n",
    "                    hand_landmarks,mphands.HAND_CONNECTIONS)\n",
    "                    b=True\n",
    "\n",
    "                    #for a in hand_landmarks:\n",
    "                    #    print(a)\n",
    "            if a ==True and b == True:\n",
    "                cv2.putText(img,\"Hand and Face Detected\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,55,200),2)\n",
    "            elif a !=True and b== True:\n",
    "                cv2.putText(img,\"Hand Detected\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,55,200),2)\n",
    "            elif a ==True and b!= True:\n",
    "                cv2.putText(img,\"Face Detected\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,55,200),2)\n",
    "\n",
    "            cv2.imshow(\"Tracker\",img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc42a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846d893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
